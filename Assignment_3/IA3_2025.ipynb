{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOK-6wmkFuv6"
      },
      "source": [
        "# Manuel Agraz Vallejo\n",
        "\n",
        "# AI534 IA3: Text Classification with BoW, Linear SVM and Naive Bayes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmsQojI61OQx"
      },
      "source": [
        "##Overview:\n",
        "You will use use the sklearn package to implement and compare classic text classification models, practicing principled evluation, tuning and interpretation. Specifically, your work will include:\n",
        "* clean preprocessing pipeline to produce BoW and TF-IDF features\n",
        "* Linear/RBF SVM and Multinomial Naive Bayes classifiers\n",
        "* Hyperparameter sweeps+plots\n",
        "* Error analysis, feature interpretatoin and short reflection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTy88JS_qJHg"
      },
      "source": [
        "## Data\n",
        "The data for this assignment consists of a natural language sentiment dataset sourced from Twitter. The first column indicates sentiment of the tweets (zero representing negative sentiment and one for positive sentiment) and the second column contains the text of the tweets.\n",
        "\n",
        "Two datasets are provided on Canvas: a training set named 'IA3-training.csv' and a validation set named 'IA3-dev.csv'. You will use the training set to build your models and the validation set to tune the parameters and observe their impacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzJPp76s04Hj"
      },
      "source": [
        "\n",
        "## What you need to submit\n",
        "1. Your completed notebook in ipynb\n",
        "2. a PDF report that includes all code outputs and figures. You can use the code block at the end of the notebook to generate a PDF export of the notebook with the outputs for your report. However, if any figures or outputs are missing, you must either:\n",
        "* Manually add the missing figures to the PDF using a PDF editor or\n",
        "* Copy your notebook contents into a Word or Google Doc, insert the missing outputs there, and export that document as a PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7zBMGIZp_Cr"
      },
      "source": [
        "First let's import the packages needed for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uxYTpds7jgwe"
      },
      "outputs": [],
      "source": [
        "# !pip install nbconvert > /dev/null 2>&1\n",
        "# !pip install pdfkit > /dev/null 2>&1\n",
        "# !apt-get install -y wkhtmltopdf > /dev/null 2>&1\n",
        "# from google.colab import files\n",
        "\n",
        "import os\n",
        "import pdfkit\n",
        "import contextlib\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53t1CXu5VK4k"
      },
      "source": [
        "Let's load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6K8DsDcwjS6",
        "outputId": "92813724-3147-4a39-cfef-19bbe1a45ad4"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# train_path = '/content/gdrive/My Drive/AI534/IA3_train.csv' # DO NOT MODIFY THIS. Please make sure your data has this exact path\n",
        "# val_path = '/content/gdrive/My Drive/AI534/IA3_val.csv' # DO NOT MODIFY THIS. Please make sure your data has this exact path\n",
        "\n",
        "train_path = './IA3_train.csv' # DO NOT MODIFY THIS. Please make sure your data has this exact path\n",
        "val_path = './IA3_val.csv' # DO NOT MODIFY THIS. Please make sure your data has this exact path\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_data = pd.read_csv(val_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDHJMP7mtF3L"
      },
      "source": [
        "# Part 0: (10 pts) Preprocessing and Initial Anlaysis\n",
        "In this part, you will take the text of the tweets and convert it to the bag-of-words (BoW) representation that can be processed by the model you will train.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfxECUTqiziU"
      },
      "source": [
        "##üìò Detailed instructions\n",
        "First, you will build your BoW vocabulary using the training set and represent your training set using *tf-idf*.\n",
        "\n",
        "Here ***tf*** stands for term frequecy and is defined as follows for a document $d$ and term $t$:\n",
        "\n",
        "$TF(t,d) = \\frac{\\mbox{Num. of times } t \\mbox{ appears in } d}{\\mbox{Total number of terms in }d}$\n",
        "\n",
        "and ***idf*** stands for inverse document frequency and is defined as follows for a term $t$ and a document collection $D$\n",
        "\n",
        "$IDF(t, D) = \\log(\\frac{N}{|\\{d\\in D: t\\in d\\}|}) $\n",
        "\n",
        "\n",
        "where $N$ is the total number of documents in $D$, and $|\\{d\\in D: t\\in d\\}|$ is the number of documents that contain term $t$.\n",
        "Specifically, you will be using the **TfidfVectorizer** class from the sklearn.feature_extraction.text package (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#). For this assignment, you should set '***stop_words=english***', other parameters can remain at their default values.\n",
        "\n",
        "The specific methods you will need to use include:\n",
        "- **`fit_transform()`** ‚Äî learns the vocabulary and inverse document frequencies from the input documents (fit), and produces their TF‚ÄìIDF representation (transform).\n",
        "- **`transform()`** ‚Äî applies the learned vocabulary and IDF values to new documents to produce their TF‚ÄìIDF representation.\n",
        "\n",
        "Both methods return a sparse matrix representation of the documents, which can be directly used by the SVM package and the Naive Bayes Package for learning. Using a sparse matrix representation is computationally efficient, especially for SVM models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6bU2fzp6NXa"
      },
      "source": [
        "## üöß Task: Build TF-IDF Features & Build Intial Word Insights\n",
        "**Your tasks:**\n",
        "\n",
        "1. Use class `TfidfVectorizer(stop_words='english')` and apply:\n",
        "   - `fit_transform()` to the **training** tweets to learn the vocabulary and IDF weights and produce the TF-IDF representation for training data\n",
        "   - `transform()` to the **validation** tweets using the learned vocabulary and IDF values and produce the TF-IDF representation of the validation data\n",
        "\n",
        "2. Print the shapes of the resulting TF‚ÄìIDF matrices for the training and validation sets.\n",
        "\n",
        "3. On the **training data only**, for each sentiment class (**positive** and **negative**):\n",
        "   - Compute a **cumulative TF‚ÄìIDF score** for each word:\n",
        "   `CumulativeTFIDF(t, C)` = $\\sum_{d \\in C} \\text{TFIDF}(t, d)$\n",
        "\n",
        "     \n",
        "   - Rank all words by this score and list the **top 20 words** in each class\n",
        "\n",
        "4. Compare the two lists and report:\n",
        "   - Words that appear in **both** lists\n",
        "   - Words **distinctive to positive** sentiment\n",
        "   - Words **distinctive to negative** sentiment\n",
        "\n",
        "> ‚úÖ Your output should include matrix shapes, the two ranked word lists (computed from training data only), and the comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KelbPLaAjT5Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF train shape: (6030, 8508)\n",
            "TF-IDF val shape: (1702, 8508)\n",
            "Vocabulary size: 8508\n",
            "\n",
            "TOP 20 WORDS FOR POSITIVE SENTIMENT\n",
            " 1. thanks              : 96.3201\n",
            " 2. thank               : 88.8932\n",
            " 3. jetblue             : 71.1725\n",
            " 4. southwestair        : 60.6011\n",
            " 5. united              : 44.4496\n",
            " 6. great               : 40.4915\n",
            " 7. americanair         : 36.8272\n",
            " 8. usairways           : 33.1923\n",
            " 9. flight              : 26.7756\n",
            "10. virginamerica       : 22.3447\n",
            "11. http                : 21.8767\n",
            "12. love                : 21.2612\n",
            "13. just                : 21.1207\n",
            "14. awesome             : 20.3262\n",
            "15. service             : 18.4246\n",
            "16. good                : 16.5092\n",
            "17. guys                : 16.2970\n",
            "18. best                : 15.4708\n",
            "19. got                 : 14.7444\n",
            "20. amazing             : 14.2398\n",
            "\n",
            "TOP 20 WORDS FOR NEGATIVE SENTIMENT\n",
            " 1. flight              : 195.5376\n",
            " 2. united              : 191.6732\n",
            " 3. usairways           : 172.0774\n",
            " 4. americanair         : 158.2648\n",
            " 5. southwestair        : 100.0555\n",
            " 6. cancelled           : 93.7536\n",
            " 7. jetblue             : 90.7270\n",
            " 8. hours               : 78.2603\n",
            " 9. hold                : 73.7652\n",
            "10. service             : 73.0355\n",
            "11. help                : 69.8108\n",
            "12. customer            : 65.2766\n",
            "13. time                : 61.2388\n",
            "14. just                : 60.1990\n",
            "15. delayed             : 60.1680\n",
            "16. hour                : 59.0244\n",
            "17. flightled           : 56.8970\n",
            "18. plane               : 55.7760\n",
            "19. flights             : 53.2911\n",
            "20. bag                 : 52.0773\n",
            "\n",
            "COMPARISON OF TOP 20 WORDS\n",
            "\n",
            "Words in BOTH lists (8):\n",
            "americanair, flight, jetblue, just, service, southwestair, united, usairways\n",
            "\n",
            "Words DISTINCTIVE to POSITIVE sentiment (12):\n",
            "amazing, awesome, best, good, got, great, guys, http, love, thank, thanks, virginamerica\n",
            "\n",
            "Words DISTINCTIVE to NEGATIVE sentiment (12):\n",
            "bag, cancelled, customer, delayed, flightled, flights, help, hold, hour, hours, plane, time\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "vectorizer = TfidfVectorizer(stop_words='english', input=\"content\")\n",
        "\n",
        "tf_idf_train = vectorizer.fit_transform(train_data['tweet'])\n",
        "\n",
        "tf_idf_val = vectorizer.transform(val_data['tweet'])\n",
        "\n",
        "# Get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(f\"TF-IDF train shape: {tf_idf_train.shape}\")\n",
        "print(f\"TF-IDF val shape: {tf_idf_val.shape}\")\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
        "\n",
        "# Split data by sentiment - convert to numpy arrays\n",
        "positive_mask = (train_data['label'] == 1).to_numpy()\n",
        "negative_mask = (train_data['label'] == 0).to_numpy()\n",
        "\n",
        "# Get TF-IDF matrices for each class\n",
        "tf_idf_positive = tf_idf_train[positive_mask]\n",
        "tf_idf_negative = tf_idf_train[negative_mask]\n",
        "\n",
        "# Compute cumulative TF-IDF for each class\n",
        "cumulative_tfidf_positive = np.asarray(tf_idf_positive.sum(axis=0)).flatten()\n",
        "cumulative_tfidf_negative = np.asarray(tf_idf_negative.sum(axis=0)).flatten()\n",
        "\n",
        "# Create rankings for positive sentiment\n",
        "positive_indices = np.argsort(cumulative_tfidf_positive)[::-1]  # Sort descending\n",
        "top_20_positive = [(feature_names[i], cumulative_tfidf_positive[i]) for i in positive_indices[:20]]\n",
        "\n",
        "# Create rankings for negative sentiment\n",
        "negative_indices = np.argsort(cumulative_tfidf_negative)[::-1]  # Sort descending\n",
        "top_20_negative = [(feature_names[i], cumulative_tfidf_negative[i]) for i in negative_indices[:20]]\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTOP 20 WORDS FOR POSITIVE SENTIMENT\")\n",
        "for rank, (word, score) in enumerate(top_20_positive, 1):\n",
        "    print(f\"{rank:2d}. {word:20s}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nTOP 20 WORDS FOR NEGATIVE SENTIMENT\")\n",
        "for rank, (word, score) in enumerate(top_20_negative, 1):\n",
        "    print(f\"{rank:2d}. {word:20s}: {score:.4f}\")\n",
        "\n",
        "# Compare the lists\n",
        "positive_words = set([word for word, _ in top_20_positive])\n",
        "negative_words = set([word for word, _ in top_20_negative])\n",
        "\n",
        "common_words = positive_words & negative_words\n",
        "positive_only = positive_words - negative_words\n",
        "negative_only = negative_words - positive_words\n",
        "\n",
        "print(\"\\nCOMPARISON OF TOP 20 WORDS\")\n",
        "print(f\"\\nWords in BOTH lists ({len(common_words)}):\")\n",
        "print(\", \".join(sorted(common_words)) if common_words else \"None\")\n",
        "\n",
        "print(f\"\\nWords DISTINCTIVE to POSITIVE sentiment ({len(positive_only)}):\")\n",
        "print(\", \".join(sorted(positive_only)) if positive_only else \"None\")\n",
        "\n",
        "print(f\"\\nWords DISTINCTIVE to NEGATIVE sentiment ({len(negative_only)}):\")\n",
        "print(\", \".join(sorted(negative_only)) if negative_only else \"None\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy9Jv2k_p3Gb"
      },
      "source": [
        "## ‚úçÔ∏è Questions\n",
        "\n",
        "1. Consider the three sets of words you identified:  \n",
        "   **(a)** common to both classes, **(b)** positive-only, and **(c)** negative-only.  \n",
        "   What patterns do you observe in each group? (e.g., emotional tone, topic, intensity)\n",
        "\n",
        "2. Suppose you train a linear sentiment classifier (e.g., linear SVM).  \n",
        "   How do you expect it to use these words?  \n",
        "   Discuss the likely **sign** and **magnitude** of the weights assigned to\n",
        "   - positive-only words  \n",
        "   - negative-only words  \n",
        "   - words appearing in both classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRedNvbKuWGb"
      },
      "source": [
        "**1.-**\n",
        "\n",
        "**The words that are common to both classes, tend to be nouns such as the names of the airlines and the word \"flight\" which make sense since most tweets towards an airline are bound to have these words. For these words there is no emotional tone and no intensity, as they don't convey emotion.**\n",
        "\n",
        "**The positive only words are mostly adjectives like: \"great\", \"amazing\", \"good\" and \"best\". All of these words have a positive tone, and moderate intensity, as they come from good reviews or praises for the companies by the customers. It's worth noting that the company \"virginamerica\" is generally asociated with postive comments which speaks good of it's service.**\n",
        "\n",
        "**The negative words are mostly related with issues that one could have with a flight such as cancellations, lost bags, delays, and long waiting hours. While the tone is negative, the words' intensity is neutral, there aren't any strong words being used against the companies, or they where probably censored.**\n",
        "\n",
        "**2.-**\n",
        "\n",
        "**I expect the classifier to use the positve-only and negative-only words as the support vectors of the boundary. As classifying these correctly is likely to lead to a correct classifcation. On the other hand words appearing in both classes would be closer to the boundary as the model would be less certain of their class.**\n",
        "\n",
        "**I expect the positive-only words to have high positve weights. For the negative-only words i expect them to have highly negative weights. These high weight values stem from the fact that the model would be able to classify them easily as they are directly related to their respective labels. For the words appearing in both class i expect their weights to be small, close to zero, as the classifier would learn that these words can't be relied on to make a classification.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMNtcBhauj2L"
      },
      "source": [
        "# Part 1. (30 pts) Linear SVM with C sweep\n",
        "\n",
        "You will train **linear SVM** models on the TF‚ÄìIDF features and tune the regularization parameter **C** over\n",
        "$C \\in \\{10^{-2}, 10^{-1}, 10^{0}, 10^{1}, 10^{2}, 10^{3}\\}.$\n",
        "\n",
        "Use `sklearn.svm.SVC` with `kernel='linear'` so that you can access the **number of support vectors** (this is not available in `LinearSVC`). The linear SVM can consume sparse TF‚ÄìIDF matrices directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5htnSLMqc3Y"
      },
      "source": [
        "### üöß Task: Linear SVM and parameter sweep\n",
        "Complete the following:\n",
        "\n",
        "1. Train a `SVC(kernel='linear')` model for each  \n",
        "   \n",
        "   $C \\in \\{10^{-2},\\,10^{-1},\\,1,\\,10,\\,10^2,\\,10^3\\}$\n",
        "\n",
        "2. For each $C$:\n",
        "   - Train on the **training** set\n",
        "   - Compute **AUROC** on **training** and **validation** sets  \n",
        "   - Record the **total number of support vectors**\n",
        "\n",
        "3. Create two plots (log-scale on the \\(C\\)-axis):\n",
        "   - **Training vs validation AUROC** as a function of \\(C\\)\n",
        "   - **Total number of support vectors** as a function of \\(C\\)\n",
        "\n",
        "4. Select and report the **best \\(C\\)** based on **validation AUROC**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NgrKbR2uEoPI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "SUMMARY TABLE\n",
            "      C  train_auroc  val_auroc  n_support_vectors\n",
            "   0.01     0.955315   0.937794               2769\n",
            "   0.10     0.966381   0.945313               2623\n",
            "   1.00     0.993342   0.953932               2340\n",
            "  10.00     0.999261   0.939581               2069\n",
            " 100.00     0.999400   0.924712               1919\n",
            "1000.00     0.999531   0.918940               1732\n",
            "\n",
            "\n",
            "Best C value: 1e+00\n",
            "Best validation AUROC: 0.9539\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here.\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn.svm\n",
        "\n",
        "# Define C values to test\n",
        "C_values = [10**-2, 10**-1, 1, 10, 10**2, 10**3]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Get labels\n",
        "y_train = train_data['label'].to_numpy()\n",
        "y_val = val_data['label'].to_numpy()\n",
        "\n",
        "for C in C_values:\n",
        "    # Train linear SVM\n",
        "    model = svm.SVC(kernel='linear', C=C, random_state=42)\n",
        "    model.fit(tf_idf_train, y_train)\n",
        "    \n",
        "    # Get decision function scores for AUROC\n",
        "    train_scores = model.decision_function(tf_idf_train)\n",
        "    val_scores = model.decision_function(tf_idf_val)\n",
        "    \n",
        "    # Calculate AUROC\n",
        "    train_auroc = roc_auc_score(y_train, train_scores)\n",
        "    val_auroc = roc_auc_score(y_val, val_scores)\n",
        "    \n",
        "    # Get number of support vectors\n",
        "    n_support_vectors = len(model.support_)\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'C': C,\n",
        "        'train_auroc': train_auroc,\n",
        "        'val_auroc': val_auroc,\n",
        "        'n_support_vectors': n_support_vectors\n",
        "    })\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display results table\n",
        "print(\"\\nSUMMARY TABLE\")\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Find best C based on validation AUROC\n",
        "best_idx = results_df['val_auroc'].idxmax()\n",
        "best_C = results_df.loc[best_idx, 'C']\n",
        "best_val_auroc = results_df.loc[best_idx, 'val_auroc']\n",
        "\n",
        "print(f\"Best C value: {best_C:.0e}\")\n",
        "print(f\"Best validation AUROC: {best_val_auroc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: AUROC vs C\n",
        "axes[0].plot(results_df['C'], results_df['train_auroc'], 'o-', \n",
        "             label='Training AUROC', linewidth=2, markersize=8)\n",
        "axes[0].plot(results_df['C'], results_df['val_auroc'], 's-', \n",
        "             label='Validation AUROC', linewidth=2, markersize=8)\n",
        "axes[0].set_xscale('log')\n",
        "axes[0].set_xlabel('C (Regularization Parameter)', fontsize=12)\n",
        "axes[0].set_ylabel('AUROC', fontsize=12)\n",
        "axes[0].set_title('AUROC vs C for Linear SVM', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Number of support vectors vs C\n",
        "axes[1].plot(results_df['C'], results_df['n_support_vectors'], 'o-', \n",
        "             color='green', linewidth=2, markersize=8)\n",
        "axes[1].set_xscale('log')\n",
        "axes[1].set_xlabel('C (Regularization Parameter)', fontsize=12)\n",
        "axes[1].set_ylabel('Number of Support Vectors', fontsize=12)\n",
        "axes[1].set_title('Support Vectors vs C for Linear SVM', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHI18q2nEqIP"
      },
      "source": [
        "## ‚úçÔ∏è Questions\n",
        "1. As the regularization parameter $C$ increases, what trends do you expect in   (a) training performance and\n",
        "  (b) validation performance?\n",
        "  Explain why in terms of underfitting vs. overfitting.  \n",
        "  Then compare your theoretical expectation to your observed results.  \n",
        "  If they differ, provide a plausible explanation.\n",
        "2. If different $C$ values produce very similar AUROC values, what principle would you use to choose between them, and why?\n",
        "\n",
        "3. How do you expect the number of support vectors to change as $C$ increases? Explain why based on the SVM objective and margin behavior.  \n",
        "Then compare your expectation to your observed results and discuss any discrepancies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9HRG17FTsM"
      },
      "source": [
        "**1.-**\n",
        "\n",
        "**As we increase the C parameter we penalize slack more and more. Penalizing slack leads to overfitting as the model tries to find a boundary where no data points have a slack greater than zero. Given increasing C leads to overfitting, I expect the training performance to increase as C increases and the validation performance to decrease.**\n",
        "\n",
        "**2.-**\n",
        "\n",
        "**If different C values produce very similar AUROC values, I would choose the smallest C value. Mainly because a smaller C values means we allow higher values of slack. This reduces overfitting and leads to a more generalizable model.**\n",
        "\n",
        "**3.-**\n",
        "\n",
        "**As C increases I expect the number of support vectors to decrease. The SVM objective seeks to maximize the margin while minimizing classification errors. When C is small, the penalty for misclassification is low, so the model prioritizes finding a wide margin even if it means allowing many points to violate the margin or be misclassified. This results in a soft margin with many support vectors - including points on the margin, within the margin, and on the wrong side.**\n",
        "\n",
        "**As C increases, the penalty for slack variables becomes larger, forcing the model to work harder to classify training points correctly. This leads to a harder margin with fewer violations. Consequently, fewer points end up being support vectors because the model can achieve correct classification for more points without needing them to define the decision boundary.**\n",
        "\n",
        "**The results confirm my expectation, the Support Vectors vs C plot shows that as we increase C, the number of suport vectors decreases.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbuVM4wIFXHs"
      },
      "source": [
        "## üöß Task ‚Äî Further Exploration of the SVM Parameter \\(C\\)\n",
        "\n",
        "After completing your initial coarse grid search for \\(C\\), refine your search to more precisely identify an effective value using validation AUROC as the evaluation criterion.\n",
        "\n",
        "Use the following guidelines:\n",
        "\n",
        "- **Boundary Expansion**  \n",
        "  If the best-performing $C$ value lies at the **edge** of your grid (e.g., the smallest or largest value tested), **extend the search range outward** to explore more extreme values.  \n",
        "  This checks whether better performance may exist beyond your initial limits.\n",
        "\n",
        "- **Local Refinement**  \n",
        "  If the best-performing $C$ value lies **within the interior** of your grid (not at an edge), **refine the search locally** by testing intermediate values near the current best.  \n",
        "  For example, if $10^1$ performs best in your initial grid, consider trying nearby values such as $10^{0.5}$ and $10^{1.5}$.\n",
        "\n",
        "- **Iterative Adjustment**  \n",
        "  Apply expansion or refinement **iteratively**.  \n",
        "  If a newly tested value becomes the best, repeat the decision process:\n",
        "  - If the new best lies at a boundary ‚Üí expand further  \n",
        "  - If the new best lies inside the range ‚Üí refine locally again  \n",
        "\n",
        "Continue exploring until additional adjustments **do not meaningfully improve** validation AUROC.\n",
        "\n",
        "**Report**\n",
        "- A small table of tried values and **validation AUROC** (sorted best-to-worst).\n",
        "- Final chosen value for $C$\n",
        "- For the best performing linear SVM model, extract the learned feature weights and report the top 10 positive-weight and top 10 negative-weight words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xVXayLXuG-7_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ITERATIVE C PARAMETER REFINEMENT\n",
            "\n",
            "Iteration 1:\n",
            "Current best C = 1.0000e+00, Val AUROC = 0.953932\n",
            "Refining locally around C = 1.0000e+00\n",
            "Testing: ['3.1623e-01', '5.6234e-01', '1.7783e+00', '3.1623e+00']\n",
            "     C = 3.1623e-01: Val AUROC = 0.952607\n",
            "     C = 5.6234e-01: Val AUROC = 0.955235\n",
            "     C = 1.7783e+00: Val AUROC = 0.951421\n",
            "     C = 3.1623e+00: Val AUROC = 0.948119\n",
            "\n",
            "Iteration 2:\n",
            "Current best C = 5.6234e-01, Val AUROC = 0.955235\n",
            "Refining locally around C = 5.6234e-01\n",
            "Testing: ['1.7783e-01']\n",
            "     C = 1.7783e-01: Val AUROC = 0.947977\n",
            "\n",
            "No meaningful improvement found. Stopping refinement.\n",
            "\n",
            "ALL TRIED C VALUES (sorted by validation AUROC)\n",
            "          C  val_auroc  train_auroc\n",
            "   0.562341   0.955235     0.988366\n",
            "   1.000000   0.953932     0.993342\n",
            "   0.316228   0.952607     0.981731\n",
            "   1.778279   0.951421     0.996315\n",
            "   3.162278   0.948119     0.997905\n",
            "   0.177828   0.947977     0.973745\n",
            "   0.100000   0.945313     0.966381\n",
            "  10.000000   0.939581     0.999261\n",
            "   0.010000   0.937794     0.955315\n",
            " 100.000000   0.924712     0.999400\n",
            "1000.000000   0.918940     0.999531\n",
            "\n",
            "FINAL CHOSEN C: 5.6234e-01\n",
            "   Validation AUROC: 0.955235\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT WORDS:\n",
            " 1. thank                    : +4.728638\n",
            " 2. thanks                   : +4.696417\n",
            " 3. great                    : +3.352659\n",
            " 4. awesome                  : +2.843458\n",
            " 5. love                     : +2.497064\n",
            " 6. amazing                  : +2.439468\n",
            " 7. best                     : +2.101440\n",
            " 8. kudos                    : +2.002055\n",
            " 9. thnx                     : +1.928469\n",
            "10. rock                     : +1.888552\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT WORDS:\n",
            " 1. hours                    : -1.824633\n",
            " 2. hold                     : -1.689157\n",
            " 3. delayed                  : -1.632176\n",
            " 4. worst                    : -1.549822\n",
            " 5. hour                     : -1.513735\n",
            " 6. website                  : -1.374268\n",
            " 7. cancelled                : -1.315785\n",
            " 8. customers                : -1.220870\n",
            " 9. ruining                  : -1.196552\n",
            "10. luggage                  : -1.126028\n",
            "\n",
            "\n",
            "FINAL MODEL PERFORMANCE\n",
            "Training AUROC:   0.988366\n",
            "Validation AUROC: 0.955235\n",
            "Number of support vectors: 2360\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "# Collect all tried C values and their validation AUROC\n",
        "all_results = []\n",
        "\n",
        "# Start with results from initial grid search\n",
        "for _, row in results_df.iterrows():\n",
        "    all_results.append({\n",
        "        'C': row['C'],\n",
        "        'val_auroc': row['val_auroc'],\n",
        "        'train_auroc': row['train_auroc']\n",
        "    })\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def evaluate_C(C_value):\n",
        "    model = svm.SVC(kernel='linear', C=C_value, random_state=42)\n",
        "    model.fit(tf_idf_train, y_train)\n",
        "    \n",
        "    train_scores = model.decision_function(tf_idf_train)\n",
        "    val_scores = model.decision_function(tf_idf_val)\n",
        "    \n",
        "    train_auroc = roc_auc_score(y_train, train_scores)\n",
        "    val_auroc = roc_auc_score(y_val, val_scores)\n",
        "    \n",
        "    return train_auroc, val_auroc, model\n",
        "\n",
        "# Iterative refinement\n",
        "print(\"ITERATIVE C PARAMETER REFINEMENT\")\n",
        "\n",
        "current_best_C = best_C\n",
        "current_best_auroc = best_val_auroc\n",
        "iteration = 1\n",
        "improvement_threshold = 0.0001  # Stop if improvement is less than this\n",
        "\n",
        "while True:\n",
        "    print(f\"\\nIteration {iteration}:\")\n",
        "    print(f\"Current best C = {current_best_C:.4e}, Val AUROC = {current_best_auroc:.6f}\")\n",
        "    \n",
        "    # Check if best C is at boundary\n",
        "    tested_C_values = [r['C'] for r in all_results]\n",
        "    is_at_lower_bound = current_best_C == min(tested_C_values)\n",
        "    is_at_upper_bound = current_best_C == max(tested_C_values)\n",
        "    \n",
        "    new_C_values = []\n",
        "    \n",
        "    if is_at_lower_bound:\n",
        "        # Expand downward\n",
        "        new_C_values = [current_best_C / 10, current_best_C / 5]\n",
        "        print(f\"Best C at lower boundary. Testing lower values: {new_C_values}\")\n",
        "    elif is_at_upper_bound:\n",
        "        # Expand upward\n",
        "        new_C_values = [current_best_C * 5, current_best_C * 10]\n",
        "        print(f\"Best C at upper boundary. Testing higher values: {new_C_values}\")\n",
        "    else:\n",
        "        # Local refinement\n",
        "        log_C = np.log10(current_best_C)\n",
        "        new_C_values = [\n",
        "            10**(log_C - 0.5),\n",
        "            10**(log_C - 0.25),\n",
        "            10**(log_C + 0.25),\n",
        "            10**(log_C + 0.5)\n",
        "        ]\n",
        "        # Filter out already tested values\n",
        "        new_C_values = [c for c in new_C_values if not any(abs(c - r['C']) < 1e-10 for r in all_results)]\n",
        "        print(f\"Refining locally around C = {current_best_C:.4e}\")\n",
        "        print(f\"Testing: {[f'{c:.4e}' for c in new_C_values]}\")\n",
        "    \n",
        "    # Test new C values\n",
        "    improved = False\n",
        "    for C_val in new_C_values:\n",
        "        # Skip if already tested\n",
        "        if any(abs(C_val - r['C']) < 1e-10 for r in all_results):\n",
        "            continue\n",
        "            \n",
        "        train_auc, val_auc, _ = evaluate_C(C_val)\n",
        "        all_results.append({\n",
        "            'C': C_val,\n",
        "            'val_auroc': val_auc,\n",
        "            'train_auroc': train_auc\n",
        "        })\n",
        "        print(f\"     C = {C_val:.4e}: Val AUROC = {val_auc:.6f}\")\n",
        "        \n",
        "        if val_auc > current_best_auroc + improvement_threshold:\n",
        "            current_best_C = C_val\n",
        "            current_best_auroc = val_auc\n",
        "            improved = True\n",
        "    \n",
        "    if not improved:\n",
        "        print(f\"\\nNo meaningful improvement found. Stopping refinement.\")\n",
        "        break\n",
        "    \n",
        "    iteration += 1\n",
        "    if iteration > 10:  # Safety limit\n",
        "        print(\"\\n Reached maximum iterations. Stopping.\")\n",
        "        break\n",
        "\n",
        "# Sort all results by validation AUROC\n",
        "all_results_df = pd.DataFrame(all_results)\n",
        "all_results_df = all_results_df.sort_values('val_auroc', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nALL TRIED C VALUES (sorted by validation AUROC)\")\n",
        "print(all_results_df.to_string(index=False))\n",
        "\n",
        "# Final best C\n",
        "final_best_C = all_results_df.iloc[0]['C']\n",
        "final_best_val_auroc = all_results_df.iloc[0]['val_auroc']\n",
        "\n",
        "print(f\"\\nFINAL CHOSEN C: {final_best_C:.4e}\")\n",
        "print(f\"   Validation AUROC: {final_best_val_auroc:.6f}\")\n",
        "\n",
        "# Train final model with best C\n",
        "final_model = svm.SVC(kernel='linear', C=final_best_C, random_state=42)\n",
        "final_model.fit(tf_idf_train, y_train)\n",
        "\n",
        "# Get feature weights (coefficients)\n",
        "weights = final_model.coef_.toarray().flatten()\n",
        "\n",
        "# Get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create word-weight pairs\n",
        "word_weights = [(feature_names[i], weights[i]) for i in range(len(weights))]\n",
        "\n",
        "# Sort by weight\n",
        "word_weights_sorted = sorted(word_weights, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 10 positive weights\n",
        "top_10_positive = word_weights_sorted[:10]\n",
        "print(\"\\nTOP 10 POSITIVE-WEIGHT WORDS:\")\n",
        "for rank, (word, weight) in enumerate(top_10_positive, 1):\n",
        "    print(f\"{rank:2d}. {word:25s}: {weight:+.6f}\")\n",
        "\n",
        "# Top 10 negative weights\n",
        "top_10_negative = word_weights_sorted[-10:][::-1]\n",
        "print(\"\\nTOP 10 NEGATIVE-WEIGHT WORDS:\")\n",
        "for rank, (word, weight) in enumerate(top_10_negative, 1):\n",
        "    print(f\"{rank:2d}. {word:25s}: {weight:+.6f}\")\n",
        "\n",
        "# Evaluate final model\n",
        "final_train_scores = final_model.decision_function(tf_idf_train)\n",
        "final_val_scores = final_model.decision_function(tf_idf_val)\n",
        "final_train_auroc = roc_auc_score(y_train, final_train_scores)\n",
        "final_val_auroc = roc_auc_score(y_val, final_val_scores)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"FINAL MODEL PERFORMANCE\")\n",
        "print(f\"Training AUROC:   {final_train_auroc:.6f}\")\n",
        "print(f\"Validation AUROC: {final_val_auroc:.6f}\")\n",
        "print(f\"Number of support vectors: {len(final_model.support_)}\")\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIozWHZjHAyj"
      },
      "source": [
        "## ‚úçÔ∏è Questions ‚Äî Comparing SVM Feature Weights to TF-IDF Words\n",
        "\n",
        "Compare the top positive and negative SVM-weighted words to the three TF-IDF groups from Part 0: top words for positive class only (positive-only), top words for negative class only (negative-only), and top words for both classes(common):\n",
        "\n",
        "1. Discuss the overlap between SVM-important words and the three lists. Did any **common** TF-IDF words appear among the most important SVM features?  Why might this happen (or not happen)?\n",
        "\n",
        "2. Identify one or two words that were ranked highly in part 0 for positive or negative sentiment, but that **did not** appear among top SVM features.  Provide one plausible explanation.\n",
        "\n",
        "3. Identify one or two **new** SVM-important words that did *not* appear prominently in the part 0 lists. Why might these words be especially helpful for classification?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfPj1DbWEi9D"
      },
      "source": [
        "**1.-**\n",
        "\n",
        "\n",
        "**Between the TF-IDF positive-only and the positive SVM-weighted words there is overlap among these words: amazing, awesome, best, great, love, thank, and thanks. This makes sense as the model gave more weight to words that are more related to higher intensities of positiveness, for example the word \"guys\" was on the TF-IDF positive only list, but not on the SVM positive list. On the other hand the clearly positive word \"kudos\" appeared on the SVM-positive list and not on the TF-IDF positive list.**\n",
        "\n",
        "**Between the TF-IDF negative-only and the negative SVM-weighted words there is overlap happened between these negative words: cancelled, delayed, hold, and hours. When looking at the words that didn't overlap, we see a situation similar to the positive words. A word clearly negative such as \"ruining\" appears in the top SVM-negative words, but not on the TF-IDF negative words. These discrepancies are due to the SVM actually going through the optimization process of finding the words that better classify tweets as positive or negative, while the TF-IDF metric is based on word frequency and has no notion of the labels.**\n",
        "\n",
        "**Finally, when looking at the TF-IDF common words, none of these overlap with any of the SVM-positve or SVM-negative words. This is because these common words do not provide useful information when trying to decide if the tweet is positive or negative, if anything they are mostly noise to the SVM model.**\n",
        "\n",
        "**2.-**\n",
        "\n",
        "**A word that was ranked 2nd in the negative sentiment and 5th in the positive sentiment TF-IDF was the word \"united\" referring to the company \"United Airlines\". This word does not appear among any of the top SVM features be it positive or negative. This is because while this company has received both positive and negative tweets, on itself, the company's name is not an indicator of positiveness or negativeness. That's why the model didn't identify it as a useful word for classification.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNGgSM6YoyMJ"
      },
      "source": [
        "# Part 2: (30 pts) Naive Bayes Classifier\n",
        "\n",
        "In this part, you will use the same TF-IDF representation of the tweets and experiment with MultiNomial Naive Bayes classifier.\n",
        "\n",
        "Multinomial Naive Bayes estimates class-conditional word probabilities from word counts. However, if a word never appears in a class in the training data, its estimated probability becomes zero, forcing the entire document probability to zero whenever that word appears.\n",
        "\n",
        "To avoid this, Naive Bayes uses a smoothing parameter ùõº, which controls how many \"fake counts\" we add to each word when estimating probabilities. Larger ùõº value means more \"fake counts\" and heavier smoothing.\n",
        "You will study how different levels of smoothing affect model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4WJi-bagnsS"
      },
      "source": [
        "## üößTask: Naive Bayes and smoothing parameters\n",
        "1. Using your TF-IDF features, train a MultinomialNB model for each\n",
        "for each  \n",
        "   \n",
        "   $\\alpha \\in \\{10,1,0.5,0.1,0.05\\}$\n",
        "\n",
        "2. For each ùõº:\n",
        "* Train on the training set\n",
        "* Compute the AUROC on the training and validation sets\n",
        "3. Create a table that report the training/validation AUROC for different $\\alpha$ values.\n",
        "\n",
        "4. Select the best ùõº based on validation AUROC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wpj-fa1puZy7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TRAINING NAIVE BAYES MODELS WITH DIFFERENT ALPHA VALUES\n",
            "Alpha =  10.00: Train AUROC = 0.918071, Val AUROC = 0.897781\n",
            "Alpha =   1.00: Train AUROC = 0.969400, Val AUROC = 0.933169\n",
            "Alpha =   0.50: Train AUROC = 0.981603, Val AUROC = 0.938936\n",
            "Alpha =   0.10: Train AUROC = 0.995461, Val AUROC = 0.937393\n",
            "Alpha =   0.05: Train AUROC = 0.997094, Val AUROC = 0.931368\n",
            "\n",
            "SUMMARY TABLE: NAIVE BAYES PERFORMANCE\n",
            " alpha  train_auroc  val_auroc\n",
            " 10.00     0.918071   0.897781\n",
            "  1.00     0.969400   0.933169\n",
            "  0.50     0.981603   0.938936\n",
            "  0.10     0.995461   0.937393\n",
            "  0.05     0.997094   0.931368\n",
            "\n",
            "Best alpha value: 0.5\n",
            "Best validation AUROC: 0.938936\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here.\n",
        "# Define alpha values to test\n",
        "alpha_values = [10, 1, 0.5, 0.1, 0.05]\n",
        "\n",
        "# Store results\n",
        "nb_results = []\n",
        "\n",
        "# Get labels (already defined from Part 1, but including for completeness)\n",
        "y_train = train_data['label'].to_numpy()\n",
        "y_val = val_data['label'].to_numpy()\n",
        "\n",
        "print(\"\\nTRAINING NAIVE BAYES MODELS WITH DIFFERENT ALPHA VALUES\")\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    # Train Multinomial Naive Bayes\n",
        "    nb_model = MultinomialNB(alpha=alpha)\n",
        "    nb_model.fit(tf_idf_train, y_train)\n",
        "    \n",
        "    # Get predicted probabilities for AUROC\n",
        "    # For Naive Bayes, we use predict_proba to get probability scores\n",
        "    train_proba = nb_model.predict_proba(tf_idf_train)[:, 1]  # Probability of positive class\n",
        "    val_proba = nb_model.predict_proba(tf_idf_val)[:, 1]\n",
        "    \n",
        "    # Calculate AUROC\n",
        "    train_auroc = roc_auc_score(y_train, train_proba)\n",
        "    val_auroc = roc_auc_score(y_val, val_proba)\n",
        "    \n",
        "    # Store results\n",
        "    nb_results.append({\n",
        "        'alpha': alpha,\n",
        "        'train_auroc': train_auroc,\n",
        "        'val_auroc': val_auroc\n",
        "    })\n",
        "    \n",
        "    print(f\"Alpha = {alpha:6.2f}: Train AUROC = {train_auroc:.6f}, Val AUROC = {val_auroc:.6f}\")\n",
        "\n",
        "# Create results DataFrame\n",
        "nb_results_df = pd.DataFrame(nb_results)\n",
        "\n",
        "# Display results table\n",
        "print(\"\\nSUMMARY TABLE: NAIVE BAYES PERFORMANCE\")\n",
        "print(nb_results_df.to_string(index=False))\n",
        "\n",
        "# Find best alpha based on validation AUROC\n",
        "best_idx = nb_results_df['val_auroc'].idxmax()\n",
        "best_alpha = nb_results_df.loc[best_idx, 'alpha']\n",
        "best_nb_val_auroc = nb_results_df.loc[best_idx, 'val_auroc']\n",
        "\n",
        "print(f\"\\nBest alpha value: {best_alpha}\")\n",
        "print(f\"Best validation AUROC: {best_nb_val_auroc:.6f}\")\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKMWOhjyucSx"
      },
      "source": [
        "## ‚úçÔ∏è Questions\n",
        "1. Based on the role of the smoothing parameter ùõº, (i.e., adding ‚Äúfake counts‚Äù), describe how you expect model performance to change as\n",
        "ùõº varies from very small to large values.\n",
        "Justify your expectation in terms of model behavior, not just the plot.\n",
        "\n",
        "2. Compare your expectation with the observed validation AUROC across\n",
        "ùõº. If the pattern does not perfectly match your prediction, suggest one plausible reason grounded in properties of text data or Naive Bayes assumptions.\n",
        "\n",
        "3. Suppose two values of ùõº produce very similar validation AUROC.\n",
        "In such a situation, what principle would you use to choose between them, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mp4R8dcu5kj"
      },
      "source": [
        "**1.-**\n",
        "\n",
        "**With low alpha values, I expect the training performance to be high as we don't modify the count as much. With higher alpha values I expect less overfitting and higher validation performance, as we add higher fake counts this can improve the model's robustness but can eventually underfit if alpha is too high.**\n",
        "\n",
        "**2.-**\n",
        "\n",
        "**The shown pattern does match my prediction. As we increase alpha, the validation performance goes up as we reduce overfitting, however at alpha=0.5 we see a breaking point that leads to underfitting as higher alpha values lead to both lower train and validation performance.**\n",
        "\n",
        "**3.-**\n",
        "\n",
        "**I would choose the lowest of the alphas as it is the ones that introduces less bias to the data. As we increase alpha, we are basically adding fake data to the probability calculations thus affecting the distribution, since the alphas give similar AUROC, reducing the amount of fake data will make our model closer to the actual observed data distribution.**\n",
        "\n",
        "**However, if the validation AUROC values are truly identical and the smaller Œ± is very close to zero, I might prefer the slightly larger Œ± for numerical stability and better generalization to completely unseen words, as extremely small Œ± can lead to numerical issues with rare or zero-count words.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIqdimuBu90y"
      },
      "source": [
        "##üößTask ‚Äî Refining the Naive Bayes Smoothing Parameter\n",
        "\n",
        "1. Expand your search for the Naive Bayes smoothing parameter \\( \\alpha \\) using the same boundary-expansion / local-refinement strategy from Part 1. Select the $\\alpha$ that yields the highest **validation AUROC**.\n",
        "\n",
        "2. Extract the weight coefficients of the linear classifier produced by Naive Bayes for different words. Specifically, for each word $w_i$, compute its weight as:$\n",
        "   \\log P(w_i \\mid y=1) - \\log P(w_i \\mid y=0)\n",
        "   $\n",
        "\n",
        "   In sklearn, these values can be obtained via `model.feature_log_prob_`.\n",
        "\n",
        "3. Compare two Naive Bayes models:\n",
        "   - Your **best $\\alpha$** based on validation AUROC\n",
        "   - A **large-smoothing model** that uses a much larger smoothing paramter (e.g., $\\alpha = 10$)\n",
        "\n",
        "   For each model, report the **top 10 positive-weight words** and **top 10 negative-weight words** with their corresponding weight values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S8PlR7WqyGok"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ITERATIVE ALPHA PARAMETER REFINEMENT\n",
            "\n",
            "Iteration 1:\n",
            "Current best alpha = 0.5000, Val AUROC = 0.938936\n",
            "Refining locally around alpha = 0.5000\n",
            "Testing: ['0.3000', '0.7500', '0.4000', '0.6000']\n",
            "alpha = 0.3000: Val AUROC = 0.940687\n",
            "alpha = 0.7500: Val AUROC = 0.936026\n",
            "alpha = 0.4000: Val AUROC = 0.940012\n",
            "alpha = 0.6000: Val AUROC = 0.937858\n",
            "\n",
            "Iteration 2:\n",
            "Current best alpha = 0.3000, Val AUROC = 0.940687\n",
            "Refining locally around alpha = 0.3000\n",
            "Testing: ['0.2000', '0.3500', '0.2400', '0.3600']\n",
            "alpha = 0.2000: Val AUROC = 0.940595\n",
            "alpha = 0.3500: Val AUROC = 0.940396\n",
            "alpha = 0.2400: Val AUROC = 0.940882\n",
            "alpha = 0.3600: Val AUROC = 0.940353\n",
            "\n",
            "Iteration 3:\n",
            "Current best alpha = 0.2400, Val AUROC = 0.940882\n",
            "Refining locally around alpha = 0.2400\n",
            "Testing: ['0.2200', '0.2700', '0.1920', '0.2880']\n",
            "alpha = 0.2200: Val AUROC = 0.940852\n",
            "alpha = 0.2700: Val AUROC = 0.940816\n",
            "alpha = 0.1920: Val AUROC = 0.940460\n",
            "alpha = 0.2880: Val AUROC = 0.940733\n",
            "\n",
            "No meaningful improvement found. Stopping refinement.\n",
            "\n",
            "\n",
            "ALL TRIED ALPHA VALUES (sorted by validation AUROC)\n",
            "\n",
            "\n",
            " alpha  val_auroc  train_auroc\n",
            " 0.240   0.940882     0.990334\n",
            " 0.220   0.940852     0.991078\n",
            " 0.270   0.940816     0.989248\n",
            " 0.288   0.940733     0.988602\n",
            " 0.300   0.940687     0.988172\n",
            " 0.200   0.940595     0.991819\n",
            " 0.192   0.940460     0.992112\n",
            " 0.350   0.940396     0.986418\n",
            " 0.360   0.940353     0.986070\n",
            " 0.400   0.940012     0.984732\n",
            " 0.500   0.938936     0.981603\n",
            " 0.600   0.937858     0.978756\n",
            " 0.100   0.937393     0.995461\n",
            " 0.750   0.936026     0.974895\n",
            " 1.000   0.933169     0.969400\n",
            " 0.050   0.931368     0.997094\n",
            "10.000   0.897781     0.918071\n",
            "\n",
            "\n",
            "\n",
            "FINAL CHOSEN ALPHA: 0.2400\n",
            "Validation AUROC: 0.940882\n",
            "\n",
            "\n",
            "EXTRACTING FEATURE WEIGHTS FROM NAIVE BAYES MODELS\n",
            "\n",
            "\n",
            "BEST ALPHA MODEL (alpha = 0.24)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT WORDS:\n",
            " 1. imaginedragons           : +3.948632\n",
            " 2. fortunemagazine          : +3.578299\n",
            " 3. rock                     : +3.564040\n",
            " 4. smooth                   : +3.531859\n",
            " 5. kudos                    : +3.514925\n",
            " 6. wonderful                : +3.374562\n",
            " 7. aww                      : +3.306575\n",
            " 8. raise                    : +3.279786\n",
            " 9. smile                    : +3.262758\n",
            "10. sweet                    : +3.244838\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT WORDS:\n",
            " 1. worst                    : -3.878324\n",
            " 2. luggage                  : -3.868331\n",
            " 3. hrs                      : -3.604410\n",
            " 4. rebook                   : -3.198873\n",
            " 5. rude                     : -3.162701\n",
            " 6. terrible                 : -3.142712\n",
            " 7. hours                    : -3.140899\n",
            " 8. ridiculous               : -3.112647\n",
            " 9. disappointed             : -3.084658\n",
            "10. money                    : -3.060641\n",
            "\n",
            "\n",
            "LARGE SMOOTHING MODEL (alpha = 10.0)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT WORDS:\n",
            " 1. thank                    : +1.687985\n",
            " 2. great                    : +1.057484\n",
            " 3. thanks                   : +1.005891\n",
            " 4. awesome                  : +0.992359\n",
            " 5. amazing                  : +0.781915\n",
            " 6. love                     : +0.691438\n",
            " 7. rock                     : +0.569302\n",
            " 8. kudos                    : +0.522281\n",
            " 9. wonderful                : +0.484541\n",
            "10. excellent                : +0.474639\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT WORDS:\n",
            " 1. cancelled                : -1.979428\n",
            " 2. hours                    : -1.978624\n",
            " 3. hold                     : -1.885529\n",
            " 4. delayed                  : -1.728122\n",
            " 5. flightled                : -1.682241\n",
            " 6. hour                     : -1.649527\n",
            " 7. flight                   : -1.603977\n",
            " 8. waiting                  : -1.530979\n",
            " 9. need                     : -1.454457\n",
            "10. don                      : -1.408860\n",
            "\n",
            "\n",
            "MODEL PERFORMANCE COMPARISON\n",
            "\n",
            "Best Alpha Model (alpha = 0.2400):\n",
            "  Training AUROC:   0.990334\n",
            "  Validation AUROC: 0.940882\n",
            "\n",
            "Large Smoothing Model (alpha = 10.0):\n",
            "  Training AUROC:   0.918071\n",
            "  Validation AUROC: 0.897781\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "# Collect all tried alpha values and their validation AUROC\n",
        "all_nb_results = []\n",
        "\n",
        "# Start with results from initial grid search\n",
        "for _, row in nb_results_df.iterrows():\n",
        "    all_nb_results.append({\n",
        "        'alpha': row['alpha'],\n",
        "        'val_auroc': row['val_auroc'],\n",
        "        'train_auroc': row['train_auroc']\n",
        "    })\n",
        "\n",
        "# Function to train and evaluate a Naive Bayes model\n",
        "def evaluate_alpha(alpha_value):\n",
        "    model = MultinomialNB(alpha=alpha_value)\n",
        "    model.fit(tf_idf_train, y_train)\n",
        "    \n",
        "    train_proba = model.predict_proba(tf_idf_train)[:, 1]\n",
        "    val_proba = model.predict_proba(tf_idf_val)[:, 1]\n",
        "    \n",
        "    train_auroc = roc_auc_score(y_train, train_proba)\n",
        "    val_auroc = roc_auc_score(y_val, val_proba)\n",
        "    \n",
        "    return train_auroc, val_auroc, model\n",
        "\n",
        "# Iterative refinement\n",
        "print(\"ITERATIVE ALPHA PARAMETER REFINEMENT\")\n",
        "\n",
        "current_best_alpha = best_alpha\n",
        "current_best_auroc = best_nb_val_auroc\n",
        "iteration = 1\n",
        "improvement_threshold = 0.0001  # Stop if improvement is less than this\n",
        "\n",
        "while True:\n",
        "    print(f\"\\nIteration {iteration}:\")\n",
        "    print(f\"Current best alpha = {current_best_alpha:.4f}, Val AUROC = {current_best_auroc:.6f}\")\n",
        "    \n",
        "    # Check if best alpha is at boundary\n",
        "    tested_alpha_values = [r['alpha'] for r in all_nb_results]\n",
        "    is_at_lower_bound = current_best_alpha == min(tested_alpha_values)\n",
        "    is_at_upper_bound = current_best_alpha == max(tested_alpha_values)\n",
        "    \n",
        "    new_alpha_values = []\n",
        "    \n",
        "    if is_at_lower_bound:\n",
        "        # Expand downward\n",
        "        new_alpha_values = [current_best_alpha / 2, current_best_alpha / 5]\n",
        "        print(f\"Best alpha at lower boundary. Testing lower values: {new_alpha_values}\")\n",
        "    elif is_at_upper_bound:\n",
        "        # Expand upward\n",
        "        new_alpha_values = [current_best_alpha * 2, current_best_alpha * 5]\n",
        "        print(f\"Best alpha at upper boundary. Testing higher values: {new_alpha_values}\")\n",
        "    else:\n",
        "        # Local refinement - test values between current and neighbors\n",
        "        sorted_alphas = sorted(tested_alpha_values)\n",
        "        current_idx = sorted_alphas.index(current_best_alpha)\n",
        "        \n",
        "        # Midpoints with neighbors\n",
        "        if current_idx > 0:\n",
        "            new_alpha_values.append((current_best_alpha + sorted_alphas[current_idx - 1]) / 2)\n",
        "        if current_idx < len(sorted_alphas) - 1:\n",
        "            new_alpha_values.append((current_best_alpha + sorted_alphas[current_idx + 1]) / 2)\n",
        "        \n",
        "        # Also try slightly closer values\n",
        "        new_alpha_values.extend([\n",
        "            current_best_alpha * 0.8,\n",
        "            current_best_alpha * 1.2\n",
        "        ])\n",
        "        \n",
        "        # Filter out already tested values\n",
        "        new_alpha_values = [a for a in new_alpha_values if not any(abs(a - r['alpha']) < 1e-10 for r in all_nb_results)]\n",
        "        print(f\"Refining locally around alpha = {current_best_alpha:.4f}\")\n",
        "        print(f\"Testing: {[f'{a:.4f}' for a in new_alpha_values]}\")\n",
        "    \n",
        "    # Test new alpha values\n",
        "    improved = False\n",
        "    for alpha_val in new_alpha_values:\n",
        "        # Skip if already tested\n",
        "        if any(abs(alpha_val - r['alpha']) < 1e-10 for r in all_nb_results):\n",
        "            continue\n",
        "            \n",
        "        train_auc, val_auc, _ = evaluate_alpha(alpha_val)\n",
        "        all_nb_results.append({\n",
        "            'alpha': alpha_val,\n",
        "            'val_auroc': val_auc,\n",
        "            'train_auroc': train_auc\n",
        "        })\n",
        "        print(f\"alpha = {alpha_val:.4f}: Val AUROC = {val_auc:.6f}\")\n",
        "        \n",
        "        if val_auc > current_best_auroc + improvement_threshold:\n",
        "            current_best_alpha = alpha_val\n",
        "            current_best_auroc = val_auc\n",
        "            improved = True\n",
        "    \n",
        "    if not improved:\n",
        "        print(f\"\\nNo meaningful improvement found. Stopping refinement.\")\n",
        "        break\n",
        "    \n",
        "    iteration += 1\n",
        "    if iteration > 10:  # Safety limit\n",
        "        print(\"\\nReached maximum iterations. Stopping.\")\n",
        "        break\n",
        "\n",
        "# Sort all results by validation AUROC\n",
        "all_nb_results_df = pd.DataFrame(all_nb_results)\n",
        "all_nb_results_df = all_nb_results_df.sort_values('val_auroc', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"ALL TRIED ALPHA VALUES (sorted by validation AUROC)\")\n",
        "print(\"\\n\")\n",
        "print(all_nb_results_df.to_string(index=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Final best alpha\n",
        "final_best_alpha = all_nb_results_df.iloc[0]['alpha']\n",
        "final_best_nb_val_auroc = all_nb_results_df.iloc[0]['val_auroc']\n",
        "\n",
        "print(f\"\\nFINAL CHOSEN ALPHA: {final_best_alpha:.4f}\")\n",
        "print(f\"Validation AUROC: {final_best_nb_val_auroc:.6f}\")\n",
        "\n",
        "# PART 2: Extract feature weights and compare models\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"EXTRACTING FEATURE WEIGHTS FROM NAIVE BAYES MODELS\")\n",
        "\n",
        "# Train best model\n",
        "best_nb_model = MultinomialNB(alpha=final_best_alpha)\n",
        "best_nb_model.fit(tf_idf_train, y_train)\n",
        "\n",
        "# Train large-smoothing model\n",
        "large_alpha = 10.0\n",
        "large_nb_model = MultinomialNB(alpha=large_alpha)\n",
        "large_nb_model.fit(tf_idf_train, y_train)\n",
        "\n",
        "# Function to extract and display top words\n",
        "def display_nb_weights(model, model_name, alpha_val):\n",
        "    # Get log probabilities for each class\n",
        "    # feature_log_prob_ has shape (n_classes, n_features)\n",
        "    # Class 0 (negative) is index 0, Class 1 (positive) is index 1\n",
        "    log_prob_pos = model.feature_log_prob_[1, :]  # P(w_i | y=1)\n",
        "    log_prob_neg = model.feature_log_prob_[0, :]  # P(w_i | y=0)\n",
        "    \n",
        "    # Compute weight: log P(w_i | y=1) - log P(w_i | y=0)\n",
        "    weights = log_prob_pos - log_prob_neg\n",
        "    \n",
        "    # Get feature names\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    \n",
        "    # Create word-weight pairs\n",
        "    word_weights = [(feature_names[i], weights[i]) for i in range(len(weights))]\n",
        "    \n",
        "    # Sort by weight\n",
        "    word_weights_sorted = sorted(word_weights, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    print(f\"{model_name} (alpha = {alpha_val})\")\n",
        "    \n",
        "    # Top 10 positive weights\n",
        "    top_10_positive = word_weights_sorted[:10]\n",
        "    print(\"\\nTOP 10 POSITIVE-WEIGHT WORDS:\")\n",
        "    for rank, (word, weight) in enumerate(top_10_positive, 1):\n",
        "        print(f\"{rank:2d}. {word:25s}: {weight:+.6f}\")\n",
        "    \n",
        "    # Top 10 negative weights\n",
        "    top_10_negative = word_weights_sorted[-10:][::-1]\n",
        "    print(\"\\nTOP 10 NEGATIVE-WEIGHT WORDS:\")\n",
        "    for rank, (word, weight) in enumerate(top_10_negative, 1):\n",
        "        print(f\"{rank:2d}. {word:25s}: {weight:+.6f}\")\n",
        "\n",
        "# Display weights for both models\n",
        "display_nb_weights(best_nb_model, \"BEST ALPHA MODEL\", final_best_alpha)\n",
        "display_nb_weights(large_nb_model, \"LARGE SMOOTHING MODEL\", large_alpha)\n",
        "\n",
        "# Evaluate both models\n",
        "print(\"\\n\")\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "\n",
        "# Best model\n",
        "best_train_proba = best_nb_model.predict_proba(tf_idf_train)[:, 1]\n",
        "best_val_proba = best_nb_model.predict_proba(tf_idf_val)[:, 1]\n",
        "best_train_auroc = roc_auc_score(y_train, best_train_proba)\n",
        "best_val_auroc = roc_auc_score(y_val, best_val_proba)\n",
        "\n",
        "print(f\"\\nBest Alpha Model (alpha = {final_best_alpha:.4f}):\")\n",
        "print(f\"  Training AUROC:   {best_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {best_val_auroc:.6f}\")\n",
        "\n",
        "# Large smoothing model\n",
        "large_train_proba = large_nb_model.predict_proba(tf_idf_train)[:, 1]\n",
        "large_val_proba = large_nb_model.predict_proba(tf_idf_val)[:, 1]\n",
        "large_train_auroc = roc_auc_score(y_train, large_train_proba)\n",
        "large_val_auroc = roc_auc_score(y_val, large_val_proba)\n",
        "\n",
        "print(f\"\\nLarge Smoothing Model (alpha = {large_alpha}):\")\n",
        "print(f\"  Training AUROC:   {large_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {large_val_auroc:.6f}\")\n",
        "\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFFuMorTyN8r"
      },
      "source": [
        "##‚úçÔ∏è Questions\n",
        "1. Compare the most important words learned by the two Naive Bayes models\n",
        "(large $\\alpha$ vs. best $\\alpha$):\n",
        "\n",
        "- What changes do you observe in the top positive/negative words and their weights when smoothing increases or decreases? Why does smoothing affect which words are emphasized?\n",
        "\n",
        "2. Now compare the most influential words from your best Naive Bayes model with those from the best linear SVM in Part 1:\n",
        "- Do you see any noticeable differences between the influential words from the two models? How might these differences influence generalization and robustness?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cniVjSXy8qA"
      },
      "source": [
        "**1.-**\n",
        "\n",
        "**I observe very little overlap between the positive words using both alphas, and the same for the negative words. Additionally as smoothing increases the weights are smaller as the probabilities approximate a uniform distribution, while in the best model with a lower alpha, the weights are higher implying that the model is more confident in those words being useful for classification.**\n",
        "\n",
        "**The smoothing affects which words are emphasized by introducing fake counts, the higher smoothing means all words will have a very similar count, thus changing the distribution to the data closer to a uniform distribution. While lower alphas, retain the original counts and the original data distribution. This difference in the distributions and thus the probabilities is what leads to different words being chosen as relevant.**\n",
        "\n",
        "**2.-**\n",
        "\n",
        "**Looking at the top 10 positive words of both models, the following overlap: kudos and rock. Looking at the top 10 negative words now, the following overlap: hours, worst and luggage. There is little overlap between the words that each model gives the most importance for classification, this implies that both models could perform differently during validation. Focusing on the positive words, the words selected by the SVM model are more generally positive such as \"great\" and \"awesome\". On the other hand, the words selected by the Naive Bayes Classifier are more specific and less general such as the words \"imaginedragons\" and \"fortunemagazine\". This to me indicates that the SVM model will be able to better deal with unseen data, as it gives importance to more general words for classification instead of very specific words in the dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUzDi8d7oo6y"
      },
      "source": [
        "# Part 3 (20 pts) Exploring bigram features\n",
        "So far you have trained models using unigram features only (single words).\n",
        "In this part, you will investigate whether including bigrams (word pairs) improves sentiment classification performance.\n",
        "Including bigrams enables the model to capture short phrases and word combinations like:\n",
        "\n",
        "* not good\n",
        "\n",
        "* very happy\n",
        "\n",
        "* delayed flight\n",
        "\n",
        "that single words alone may not fully express."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwiQqMXh3slr"
      },
      "source": [
        "## üöß Task ‚Äî Bigram Feature Exploration\n",
        "\n",
        "1. Construct and evaluate two TF-IDF feature representations:\n",
        "\n",
        "- Using both Unigrams + Bigrams by setting `ngram_range = (1, 2)`\n",
        "\n",
        "- Using Bigrams only by setting `ngram_range = (2, 2)`\n",
        "\n",
        "2. For each representation,\n",
        "- train both linear SVM and Multinomial Naive Bayes, using the selected parameters from Parts 1 and 2 (note here you are not asked to retune ùê∂ or ùõº as the goal is to isolate the effect of changing the feature space only.).\n",
        "- Compute and report training and validation AUROC for each representation\n",
        "\n",
        "- Extract and report the top positive and negative features (similar to Parts 1 & 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "py_Io-q49TmB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Creating Unigrams + Bigrams representation (ngram_range=(1,2))\n",
            "Unigrams+Bigrams - Train shape: (6030, 49009)\n",
            "Unigrams+Bigrams - Val shape: (1702, 49009)\n",
            "Unigrams+Bigrams - Vocabulary size: 49009\n",
            "\n",
            "\n",
            "Creating Bigrams-only representation (ngram_range=(2,2))\n",
            "Bigrams-only - Train shape: (6030, 40501)\n",
            "Bigrams-only - Val shape: (1702, 40501)\n",
            "Bigrams-only - Vocabulary size: 40501\n",
            "\n",
            "\n",
            "TRAINING MODELS WITH UNIGRAMS + BIGRAMS\n",
            "\n",
            "Training Linear SVM (C=5.6234e-01)\n",
            "  Training AUROC:   0.996890\n",
            "  Validation AUROC: 0.952225\n",
            "  Support vectors:  3369\n",
            "\n",
            "Training Multinomial Naive Bayes (alpha=0.2400)\n",
            "  Training AUROC:   0.999790\n",
            "  Validation AUROC: 0.944681\n",
            "\n",
            "\n",
            "TRAINING MODELS WITH BIGRAMS ONLY\n",
            "\n",
            "Training Linear SVM (C=5.6234e-01)\n",
            "  Training AUROC:   0.999479\n",
            "  Validation AUROC: 0.869215\n",
            "  Support vectors:  5413\n",
            "\n",
            "Training Multinomial Naive Bayes (alpha=0.2400)\n",
            "  Training AUROC:   0.999967\n",
            "  Validation AUROC: 0.874025\n",
            "\n",
            "\n",
            "PERFORMANCE COMPARISON SUMMARY\n",
            "    Feature Type       Model  Train AUROC  Val AUROC  Vocab Size\n",
            "   Unigrams Only  Linear SVM     0.988366   0.955235        8508\n",
            "   Unigrams Only Naive Bayes     0.990334   0.940882        8508\n",
            "Unigrams+Bigrams  Linear SVM     0.996890   0.952225       49009\n",
            "Unigrams+Bigrams Naive Bayes     0.999790   0.944681       49009\n",
            "    Bigrams Only  Linear SVM     0.999479   0.869215       40501\n",
            "    Bigrams Only Naive Bayes     0.999967   0.874025       40501\n",
            "\n",
            "\n",
            "TOP FEATURES - UNIGRAMS + BIGRAMS (Linear SVM)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT FEATURES:\n",
            " 1. thank                              : +5.727424\n",
            " 2. thanks                             : +5.566020\n",
            " 3. great                              : +3.768645\n",
            " 4. awesome                            : +3.079713\n",
            " 5. love                               : +2.851644\n",
            " 6. amazing                            : +2.658211\n",
            " 7. best                               : +2.146072\n",
            " 8. southwestair                       : +1.841114\n",
            " 9. virginamerica                      : +1.813753\n",
            "10. kudos                              : +1.692440\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT FEATURES:\n",
            " 1. hours                              : -1.701920\n",
            " 2. delayed                            : -1.459005\n",
            " 3. hour                               : -1.206413\n",
            " 4. worst                              : -1.205903\n",
            " 5. hold                               : -1.180951\n",
            " 6. cancelled                          : -1.159873\n",
            " 7. website                            : -0.998090\n",
            " 8. luggage                            : -0.959050\n",
            " 9. bag                                : -0.925341\n",
            "10. customers                          : -0.912133\n",
            "\n",
            "\n",
            "TOP FEATURES - UNIGRAMS + BIGRAMS (Naive Bayes)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT FEATURES:\n",
            " 1. great thank                        : +3.452874\n",
            " 2. jetblue thank                      : +3.368158\n",
            " 3. quick response                     : +3.350543\n",
            " 4. jetblue thanks                     : +3.212360\n",
            " 5. jetblue awesome                    : +3.161988\n",
            " 6. thank help                         : +3.159320\n",
            " 7. virginamerica thank                : +3.145902\n",
            " 8. southwestair thank                 : +3.121106\n",
            " 9. virginamerica thanks               : +3.089494\n",
            "10. united thnx                        : +3.075383\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT FEATURES:\n",
            " 1. worst                              : -3.805017\n",
            " 2. luggage                            : -3.798420\n",
            " 3. hrs                                : -3.531326\n",
            " 4. hours                              : -3.438646\n",
            " 5. hold                               : -3.164311\n",
            " 6. rude                               : -3.122509\n",
            " 7. rebook                             : -3.098029\n",
            " 8. terrible                           : -3.081044\n",
            " 9. hold hours                         : -3.073238\n",
            "10. delayed                            : -3.053766\n",
            "\n",
            "\n",
            "TOP FEATURES - BIGRAMS ONLY (Linear SVM)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT BIGRAMS:\n",
            " 1. jetblue thanks                     : +3.164276\n",
            " 2. southwestair thanks                : +2.845960\n",
            " 3. jetblue thank                      : +2.620203\n",
            " 4. southwestair thank                 : +2.407598\n",
            " 5. united thank                       : +2.334887\n",
            " 6. americanair thanks                 : +2.086696\n",
            " 7. great flight                       : +1.920790\n",
            " 8. americanair thank                  : +1.898739\n",
            " 9. virginamerica thank                : +1.830209\n",
            "10. united thanks                      : +1.830054\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT BIGRAMS:\n",
            " 1. cancelled flightled                : -0.715783\n",
            " 2. delayed hours                      : -0.631569\n",
            " 3. late flight                        : -0.585804\n",
            " 4. cancelled flighted                 : -0.527100\n",
            " 5. hold hour                          : -0.482223\n",
            " 6. flight delayed                     : -0.479724\n",
            " 7. thanks finally                     : -0.470571\n",
            " 8. cancelled flight                   : -0.459042\n",
            " 9. thanks ruining                     : -0.452220\n",
            "10. flight leaving                     : -0.414461\n",
            "\n",
            "\n",
            "TOP FEATURES - BIGRAMS ONLY (Naive Bayes)\n",
            "\n",
            "TOP 10 POSITIVE-WEIGHT BIGRAMS:\n",
            " 1. great thank                        : +3.573130\n",
            " 2. quick response                     : +3.515099\n",
            " 3. jetblue thank                      : +3.410699\n",
            " 4. united thnx                        : +3.324012\n",
            " 5. virginamerica thank                : +3.321471\n",
            " 6. jetblue awesome                    : +3.303228\n",
            " 7. thank help                         : +3.278071\n",
            " 8. virginamerica thanks               : +3.235252\n",
            " 9. guys rock                          : +3.224851\n",
            "10. jetblue thanks                     : +3.203967\n",
            "\n",
            "TOP 10 NEGATIVE-WEIGHT BIGRAMS:\n",
            " 1. hold hours                         : -3.307953\n",
            " 2. hold hour                          : -3.153188\n",
            " 3. cancelled flightled                : -3.082241\n",
            " 4. ve hold                            : -2.985020\n",
            " 5. usairways hold                     : -2.939126\n",
            " 6. cancelled flight                   : -2.838032\n",
            " 7. worst customer                     : -2.836736\n",
            " 8. usairways ve                       : -2.783014\n",
            " 9. hours late                         : -2.716558\n",
            "10. flighted flight                    : -2.692353\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here.\n",
        "\n",
        "# Unigrams + Bigrams (1,2)\n",
        "print(\"\\n\")\n",
        "print(\"Creating Unigrams + Bigrams representation (ngram_range=(1,2))\")\n",
        "\n",
        "vectorizer_unigram_bigram = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
        "tf_idf_train_ub = vectorizer_unigram_bigram.fit_transform(train_data['tweet'])\n",
        "tf_idf_val_ub = vectorizer_unigram_bigram.transform(val_data['tweet'])\n",
        "\n",
        "print(f\"Unigrams+Bigrams - Train shape: {tf_idf_train_ub.shape}\")\n",
        "print(f\"Unigrams+Bigrams - Val shape: {tf_idf_val_ub.shape}\")\n",
        "print(f\"Unigrams+Bigrams - Vocabulary size: {len(vectorizer_unigram_bigram.vocabulary_)}\")\n",
        "\n",
        "# Bigrams only (2,2)\n",
        "print(\"\\n\")\n",
        "print(\"Creating Bigrams-only representation (ngram_range=(2,2))\")\n",
        "\n",
        "vectorizer_bigram = TfidfVectorizer(stop_words='english', ngram_range=(2, 2))\n",
        "tf_idf_train_b = vectorizer_bigram.fit_transform(train_data['tweet'])\n",
        "tf_idf_val_b = vectorizer_bigram.transform(val_data['tweet'])\n",
        "\n",
        "print(f\"Bigrams-only - Train shape: {tf_idf_train_b.shape}\")\n",
        "print(f\"Bigrams-only - Val shape: {tf_idf_val_b.shape}\")\n",
        "print(f\"Bigrams-only - Vocabulary size: {len(vectorizer_bigram.vocabulary_)}\")\n",
        "\n",
        "# 2. Train models with Unigrams + Bigrams\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TRAINING MODELS WITH UNIGRAMS + BIGRAMS\")\n",
        "\n",
        "# Linear SVM with best C from Part 1\n",
        "print(f\"\\nTraining Linear SVM (C={final_best_C:.4e})\")\n",
        "svm_ub = svm.SVC(kernel='linear', C=final_best_C, random_state=42)\n",
        "svm_ub.fit(tf_idf_train_ub, y_train)\n",
        "\n",
        "svm_ub_train_scores = svm_ub.decision_function(tf_idf_train_ub)\n",
        "svm_ub_val_scores = svm_ub.decision_function(tf_idf_val_ub)\n",
        "svm_ub_train_auroc = roc_auc_score(y_train, svm_ub_train_scores)\n",
        "svm_ub_val_auroc = roc_auc_score(y_val, svm_ub_val_scores)\n",
        "\n",
        "print(f\"  Training AUROC:   {svm_ub_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {svm_ub_val_auroc:.6f}\")\n",
        "print(f\"  Support vectors:  {len(svm_ub.support_)}\")\n",
        "\n",
        "# Multinomial Naive Bayes with best alpha from Part 2\n",
        "print(f\"\\nTraining Multinomial Naive Bayes (alpha={final_best_alpha:.4f})\")\n",
        "nb_ub = MultinomialNB(alpha=final_best_alpha)\n",
        "nb_ub.fit(tf_idf_train_ub, y_train)\n",
        "\n",
        "nb_ub_train_proba = nb_ub.predict_proba(tf_idf_train_ub)[:, 1]\n",
        "nb_ub_val_proba = nb_ub.predict_proba(tf_idf_val_ub)[:, 1]\n",
        "nb_ub_train_auroc = roc_auc_score(y_train, nb_ub_train_proba)\n",
        "nb_ub_val_auroc = roc_auc_score(y_val, nb_ub_val_proba)\n",
        "\n",
        "print(f\"  Training AUROC:   {nb_ub_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {nb_ub_val_auroc:.6f}\")\n",
        "\n",
        "# 3. Train models with Bigrams only\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TRAINING MODELS WITH BIGRAMS ONLY\")\n",
        "\n",
        "# Linear SVM\n",
        "print(f\"\\nTraining Linear SVM (C={final_best_C:.4e})\")\n",
        "svm_b = svm.SVC(kernel='linear', C=final_best_C, random_state=42)\n",
        "svm_b.fit(tf_idf_train_b, y_train)\n",
        "\n",
        "svm_b_train_scores = svm_b.decision_function(tf_idf_train_b)\n",
        "svm_b_val_scores = svm_b.decision_function(tf_idf_val_b)\n",
        "svm_b_train_auroc = roc_auc_score(y_train, svm_b_train_scores)\n",
        "svm_b_val_auroc = roc_auc_score(y_val, svm_b_val_scores)\n",
        "\n",
        "print(f\"  Training AUROC:   {svm_b_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {svm_b_val_auroc:.6f}\")\n",
        "print(f\"  Support vectors:  {len(svm_b.support_)}\")\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "print(f\"\\nTraining Multinomial Naive Bayes (alpha={final_best_alpha:.4f})\")\n",
        "nb_b = MultinomialNB(alpha=final_best_alpha)\n",
        "nb_b.fit(tf_idf_train_b, y_train)\n",
        "\n",
        "nb_b_train_proba = nb_b.predict_proba(tf_idf_train_b)[:, 1]\n",
        "nb_b_val_proba = nb_b.predict_proba(tf_idf_val_b)[:, 1]\n",
        "nb_b_train_auroc = roc_auc_score(y_train, nb_b_train_proba)\n",
        "nb_b_val_auroc = roc_auc_score(y_val, nb_b_val_proba)\n",
        "\n",
        "print(f\"  Training AUROC:   {nb_b_train_auroc:.6f}\")\n",
        "print(f\"  Validation AUROC: {nb_b_val_auroc:.6f}\")\n",
        "\n",
        "# 4. Summary comparison table\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
        "\n",
        "comparison_results = pd.DataFrame([\n",
        "    {\n",
        "        'Feature Type': 'Unigrams Only',\n",
        "        'Model': 'Linear SVM',\n",
        "        'Train AUROC': final_train_auroc,\n",
        "        'Val AUROC': final_val_auroc,\n",
        "        'Vocab Size': len(vectorizer.vocabulary_)\n",
        "    },\n",
        "    {\n",
        "        'Feature Type': 'Unigrams Only',\n",
        "        'Model': 'Naive Bayes',\n",
        "        'Train AUROC': best_train_auroc,\n",
        "        'Val AUROC': best_val_auroc,\n",
        "        'Vocab Size': len(vectorizer.vocabulary_)\n",
        "    },\n",
        "    {\n",
        "        'Feature Type': 'Unigrams+Bigrams',\n",
        "        'Model': 'Linear SVM',\n",
        "        'Train AUROC': svm_ub_train_auroc,\n",
        "        'Val AUROC': svm_ub_val_auroc,\n",
        "        'Vocab Size': len(vectorizer_unigram_bigram.vocabulary_)\n",
        "    },\n",
        "    {\n",
        "        'Feature Type': 'Unigrams+Bigrams',\n",
        "        'Model': 'Naive Bayes',\n",
        "        'Train AUROC': nb_ub_train_auroc,\n",
        "        'Val AUROC': nb_ub_val_auroc,\n",
        "        'Vocab Size': len(vectorizer_unigram_bigram.vocabulary_)\n",
        "    },\n",
        "    {\n",
        "        'Feature Type': 'Bigrams Only',\n",
        "        'Model': 'Linear SVM',\n",
        "        'Train AUROC': svm_b_train_auroc,\n",
        "        'Val AUROC': svm_b_val_auroc,\n",
        "        'Vocab Size': len(vectorizer_bigram.vocabulary_)\n",
        "    },\n",
        "    {\n",
        "        'Feature Type': 'Bigrams Only',\n",
        "        'Model': 'Naive Bayes',\n",
        "        'Train AUROC': nb_b_train_auroc,\n",
        "        'Val AUROC': nb_b_val_auroc,\n",
        "        'Vocab Size': len(vectorizer_bigram.vocabulary_)\n",
        "    }\n",
        "])\n",
        "\n",
        "print(comparison_results.to_string(index=False))\n",
        "\n",
        "# 5. Extract top features for Unigrams+Bigrams models\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TOP FEATURES - UNIGRAMS + BIGRAMS (Linear SVM)\")\n",
        "\n",
        "# Get SVM weights\n",
        "weights_ub = svm_ub.coef_.toarray().flatten()\n",
        "feature_names_ub = vectorizer_unigram_bigram.get_feature_names_out()\n",
        "word_weights_ub = [(feature_names_ub[i], weights_ub[i]) for i in range(len(weights_ub))]\n",
        "word_weights_ub_sorted = sorted(word_weights_ub, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 10 positive\n",
        "print(\"\\nTOP 10 POSITIVE-WEIGHT FEATURES:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_ub_sorted[:10], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "# Top 10 negative\n",
        "print(\"\\nTOP 10 NEGATIVE-WEIGHT FEATURES:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_ub_sorted[-10:][::-1], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TOP FEATURES - UNIGRAMS + BIGRAMS (Naive Bayes)\")\n",
        "\n",
        "# Get NB weights\n",
        "log_prob_pos_ub = nb_ub.feature_log_prob_[1, :]\n",
        "log_prob_neg_ub = nb_ub.feature_log_prob_[0, :]\n",
        "weights_nb_ub = log_prob_pos_ub - log_prob_neg_ub\n",
        "word_weights_nb_ub = [(feature_names_ub[i], weights_nb_ub[i]) for i in range(len(weights_nb_ub))]\n",
        "word_weights_nb_ub_sorted = sorted(word_weights_nb_ub, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 10 positive\n",
        "print(\"\\nTOP 10 POSITIVE-WEIGHT FEATURES:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_nb_ub_sorted[:10], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "# Top 10 negative\n",
        "print(\"\\nTOP 10 NEGATIVE-WEIGHT FEATURES:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_nb_ub_sorted[-10:][::-1], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "# 6. Extract top features for Bigrams-only models\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TOP FEATURES - BIGRAMS ONLY (Linear SVM)\")\n",
        "\n",
        "# Get SVM weights\n",
        "weights_b = svm_b.coef_.toarray().flatten()\n",
        "feature_names_b = vectorizer_bigram.get_feature_names_out()\n",
        "word_weights_b = [(feature_names_b[i], weights_b[i]) for i in range(len(weights_b))]\n",
        "word_weights_b_sorted = sorted(word_weights_b, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 10 positive\n",
        "print(\"\\nTOP 10 POSITIVE-WEIGHT BIGRAMS:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_b_sorted[:10], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "# Top 10 negative\n",
        "print(\"\\nTOP 10 NEGATIVE-WEIGHT BIGRAMS:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_b_sorted[-10:][::-1], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"TOP FEATURES - BIGRAMS ONLY (Naive Bayes)\")\n",
        "\n",
        "# Get NB weights\n",
        "log_prob_pos_b = nb_b.feature_log_prob_[1, :]\n",
        "log_prob_neg_b = nb_b.feature_log_prob_[0, :]\n",
        "weights_nb_b = log_prob_pos_b - log_prob_neg_b\n",
        "word_weights_nb_b = [(feature_names_b[i], weights_nb_b[i]) for i in range(len(weights_nb_b))]\n",
        "word_weights_nb_b_sorted = sorted(word_weights_nb_b, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 10 positive\n",
        "print(\"\\nTOP 10 POSITIVE-WEIGHT BIGRAMS:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_nb_b_sorted[:10], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")\n",
        "\n",
        "# Top 10 negative\n",
        "print(\"\\nTOP 10 NEGATIVE-WEIGHT BIGRAMS:\")\n",
        "for rank, (feature, weight) in enumerate(word_weights_nb_b_sorted[-10:][::-1], 1):\n",
        "    print(f\"{rank:2d}. {feature:35s}: {weight:+.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQRrdCT59U3v"
      },
      "source": [
        "## ‚úçÔ∏è Questions.\n",
        "1. Did including bigrams (in addition to unigrams) improve performance compared to using unigram alone? Why might bigrams help in sentiment classification?\n",
        "\n",
        "2. How did the bigrams-only model perform relative to unigrams+bigrams or unigram-only? Provide an explanation for your observed differences.\n",
        "\n",
        "3. Inspect the most influential bigram features. Provide one example where the bigram carries more sentiment meaning than either unigram alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1.-**\n",
        "**Unigrams+Bigrams with Naive Bayes performed slightly better on validation that it's Unigrams Only counterpart. However, when comparing the SVM models the Unigrams Only model is slightly better in validation than the Unigrams+Bigrams model. Theoretically bigrams should generally improve performance given that bigrams capture more information than unigrams, in practice we see that both models are generally very similar in performance**\n",
        "\n",
        "**2.-**\n",
        "**The Bigrams-only model actually performed worse than both Unigrams-Only and Unigrams+Bigrams in validation performance. My hypothesis is that this occurs due to the rarity on the bigrams in the data, being more infrequent than unigrams. Additionally, using bigrams increases the size of the vocabulary to 40k which added to the data sparsity most likely lead to overfitting as we see a high training performance when using only Bigrams.**\n",
        "\n",
        "**3.-**\n",
        "**One of the top-10 bigrams \"guys rock\" is only positive when both words are together as it probably comes from the phrase \"you guys rock\". Individually \"rock\" and \"guys\" don't really convey any sentiment. Additionally only the individual word \"rock\" appears as a top-10 positive word in the Unigram Linear SVM, while the word guys only comes up when the bigram is considered.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHh7zJx00d8L"
      },
      "source": [
        "#Part 4. (10 pts) In-class competition\n",
        "We will host a in-class competition using the IA3 data. To participate in this competition, use the following link: https://www.kaggle.com/t/a6382751cf574a7a85b9e9adb8384777\n",
        "\n",
        "**Model restriction.** For this competition, you are required to use SVM and Naive Bayes models.\n",
        "\n",
        "**Exploration encouraged**. Here are some ideas you are welcome to explore:\n",
        "- **Model variants**  \n",
        "  Try alternative settings for SVM or Naive Bayes, or other simple linear models.\n",
        "\n",
        "- **Feature engineering**  \n",
        "  Add, remove, or transform text features (e.g., character n-grams, stopword decisions, emoji handling).\n",
        "\n",
        "- **Data balancing strategies**  \n",
        "  Try upsampling minority class examples or downsampling the majority class.\n",
        "\n",
        "- **Additional preprocessing**  \n",
        "  Experiment with handling punctuation, URLs, user handles, emojis, or casing.\n",
        "\n",
        "- **Additional hyperparameter tuning**  \n",
        "  If useful, continue refining $C$ or $\\alpha$, or explore related knobs.\n",
        "\n",
        "**Team work.** You should continue working in the same team for this competition. The training and validation data provided on the kaggle site are the same as the IA3 assignment.\n",
        "\n",
        "**Evaluation.** To participate, you will apply your trained/tuned model to the test data provided on kaggle (which does not contian the label column), and generate a prediction score for each example. You can consult the sample submission file on Kaggle for the right format for the submission. The metric used for this competition is AUROC due to imbalanced class distribution.\n",
        "\n",
        "There are two parts to the score you will see on kaggle. The performance reported on the public leaderboard and a score reported on the private leaderboard. The public leader board scores are visible through out the competition and you can use it as an external validation to help you refine your model design and tune the model. The private leader board scores are evaluated using a separate set of test data as the final performance evaluation and will be released only after the competition is closed.\n",
        "\n",
        "**Points and bonus points.** You will get the full 10 points if you\n",
        "\n",
        "- Submitting predictions to the competition (at least one successful submission)\n",
        "\n",
        "- Achieving non-trivial performance (i.e., outperforming a simple baseline ‚Äî not necessarily high ranking)\n",
        "\n",
        "- Completing a brief write-up describing:\n",
        "\n",
        "  - what you tried\n",
        "\n",
        "  - which change(s) had the largest effect on performance (positive or negative)\n",
        "\n",
        "  - what you learned from the process\n",
        "\n",
        "You will get **3 nonus points** if your team **scored top 3** on the private leader board, or entered **the largest number of unique submissions** (unique sores).\n",
        "\n",
        "No late submission. The competition will be closed at 11:59 pm of the due date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KAGGLE COMPETITION - DATA OVERVIEW\n",
            "\n",
            "Test data shape: (3809, 2)\n",
            "Test columns: ['id', 'tweet']\n",
            "\n",
            "First few test tweets:\n",
            "0    @AmericanAir Hopefully you ll see bad ones as ...\n",
            "1    @SouthwestAir Cancelled Flightled my flight wi...\n",
            "2    @USAirways please help! No bags, no way to get...\n",
            "3    @JetBlue I'm disappointed my flight was Cancel...\n",
            "4    @JetBlue flight attendant Wendi on Flt 127 on ...\n",
            "Name: tweet, dtype: object\n",
            "\n",
            "CLASS DISTRIBUTION IN TRAINING DATA\n",
            "\n",
            "Negative (0): 4795 (79.5%)\n",
            "Positive (1): 1235 (20.5%)\n",
            "Imbalance ratio: 3.88:1\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Load test data\n",
        "test_path = './IA3_Kaggletest_xonly.csv'\n",
        "test_data = pd.read_csv(test_path, encoding='iso-8859-1')\n",
        "\n",
        "print(\"KAGGLE COMPETITION - DATA OVERVIEW\")\n",
        "print(f\"\\nTest data shape: {test_data.shape}\")\n",
        "print(f\"Test columns: {test_data.columns.tolist()}\")\n",
        "print(\"\\nFirst few test tweets:\")\n",
        "print(test_data['tweet'].head())\n",
        "\n",
        "# Check class balance in training data\n",
        "print(\"\\nCLASS DISTRIBUTION IN TRAINING DATA\")\n",
        "class_counts = train_data['label'].value_counts()\n",
        "print(f\"\\nNegative (0): {class_counts[0]} ({class_counts[0]/len(train_data)*100:.1f}%)\")\n",
        "print(f\"Positive (1): {class_counts[1]} ({class_counts[1]/len(train_data)*100:.1f}%)\")\n",
        "print(f\"Imbalance ratio: {class_counts[0]/class_counts[1]:.2f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPROCESSING EXAMPLES\n",
            "\n",
            "Example 1:\n",
            "Original:  @SouthwestAir because according to the flight attendant my husband doesn't talk english, when the fa\n",
            "Processed: because according to the flight attendant my husband doesn't talk english, when the fact is that he \n",
            "\n",
            "Example 2:\n",
            "Original:  @united why do I check in online if I still have to wait in line for an hour to \"check in\" at counte\n",
            "Processed: why do i check in online if i still have to wait in line for an hour to \"check in\" at counter? #fuck\n",
            "\n",
            "Example 3:\n",
            "Original:  @AmericanAir Aww Thanks AA..DFW was on GMA up here this AM..so i understand ..Btw A.A is my Airline \n",
            "Processed: aww thanks aa..dfw was on gma up here this am..so i understand ..btw a.a is my airline when im able \n"
          ]
        }
      ],
      "source": [
        "# Enhanced preprocessing function\n",
        "\n",
        "def preprocess_text(text, keep_emojis=False, remove_handles=True, remove_urls=True):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove URLs\n",
        "    if remove_urls:\n",
        "        text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    \n",
        "    # Remove user handles\n",
        "    if remove_handles:\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "    \n",
        "    # Remove emojis completely\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Test preprocessing\n",
        "print(\"PREPROCESSING EXAMPLES\")\n",
        "sample_tweets = [\n",
        "    train_data['tweet'].iloc[0],\n",
        "    train_data['tweet'].iloc[100],\n",
        "    train_data['tweet'].iloc[200]\n",
        "]\n",
        "\n",
        "for i, tweet in enumerate(sample_tweets, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Original:  {tweet[:100]}\")\n",
        "    print(f\"Processed: {preprocess_text(tweet)[:100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combining train and validation sets for final model\n",
            "Combined dataset size: 7732\n",
            "Class distribution:\n",
            "label\n",
            "0    6149\n",
            "1    1583\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Training final no pre-processing SVM model ---\n",
            "Training complete.\n",
            "\n",
            "--- Training final pre-processing SVM model ---\n",
            "Training complete.\n",
            "\n",
            "--- Training final no pre-processing Naive Bayes model ---\n",
            "Training complete.\n",
            "\n",
            "--- Training final pre-processing Naive Bayes model ---\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Combine train + validation for final training\n",
        "print(\"Combining train and validation sets for final model\")\n",
        "combined_data = pd.concat([train_data, val_data], ignore_index=True)\n",
        "combined_preprocessed = combined_data['tweet'].apply(preprocess_text)\n",
        "y_combined = combined_data['label'].to_numpy()\n",
        "\n",
        "print(f\"Combined dataset size: {len(combined_data)}\")\n",
        "print(f\"Class distribution:\")\n",
        "print(combined_data['label'].value_counts())\n",
        "\n",
        "# Retrain best model on combined data\n",
        "vectorizer_final = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=30000,\n",
        "    min_df=2,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "vectorizer_prepro_final = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=30000,\n",
        "    min_df=2,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_combined = vectorizer_final.fit_transform(combined_data['tweet'])\n",
        "\n",
        "X_prepro_combined = vectorizer_prepro_final.fit_transform(combined_preprocessed)\n",
        "\n",
        "print(\"\\n--- Training final no pre-processing SVM model ---\")\n",
        "svm_final = svm.SVC(kernel='linear', C=final_best_C, random_state=42)\n",
        "svm_final.fit(X_combined, y_combined)\n",
        "print(f\"Training complete.\")\n",
        "\n",
        "print(\"\\n--- Training final pre-processing SVM model ---\")\n",
        "svm_prepo_final = svm.SVC(kernel='linear', C=final_best_C, random_state=42)\n",
        "svm_prepo_final.fit(X_prepro_combined, y_combined)\n",
        "print(f\"Training complete.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training final no pre-processing Naive Bayes model ---\")\n",
        "nb_final = MultinomialNB(alpha=final_best_alpha)\n",
        "nb_final.fit(X_combined, y_combined)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n--- Training final pre-processing Naive Bayes model ---\")\n",
        "nb_prepro_final = MultinomialNB(alpha=final_best_alpha)\n",
        "nb_prepro_final.fit(X_prepro_combined, y_combined)\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATING KAGGLE SUBMISSION FILES\n",
            "\n",
            "Test data shapes:\n",
            "  Preprocessed: (3809, 8935)\n",
            "  Original:     (3809, 10265)\n",
            "\n",
            "SUBMISSIONS USING PREPROCESSED DATA\n",
            "\n",
            "1. SVM (preprocessed) submission\n",
            "  Saved: submission_svm_preprocessed.csv\n",
            "\n",
            "2. Naive Bayes (preprocessed) submission\n",
            "  Saved: submission_nb_preprocessed.csv\n",
            "\n",
            "3. Ensemble (preprocessed) submission\n",
            "  Saved: submission_ensemble_preprocessed.csv\n",
            "\n",
            "SUBMISSIONS USING ORIGINAL DATA (NO PREPROCESSING)\n",
            "\n",
            "4. SVM (original) submission\n",
            "  Saved: submission_svm_original.csv\n",
            "\n",
            "5. Naive Bayes (original) submission\n",
            "  Saved: submission_nb_original.csv\n",
            "\n",
            "6. Ensemble (original) submission\n",
            "  Saved: submission_ensemble_original.csv\n"
          ]
        }
      ],
      "source": [
        "# Generate Kaggle submissions\n",
        "print(\"GENERATING KAGGLE SUBMISSION FILES\")\n",
        "\n",
        "# Preprocess test data\n",
        "test_preprocessed_final = test_data['tweet'].apply(preprocess_text)\n",
        "\n",
        "# Transform test data using both vectorizers\n",
        "X_test_prepro_final = vectorizer_prepro_final.transform(test_preprocessed_final)\n",
        "X_test_final = vectorizer_final.transform(test_data['tweet'])\n",
        "\n",
        "print(\"\\nTest data shapes:\")\n",
        "print(f\"  Preprocessed: {X_test_prepro_final.shape}\")\n",
        "print(f\"  Original:     {X_test_final.shape}\")\n",
        "\n",
        "print(\"\\nSUBMISSIONS USING PREPROCESSED DATA\")\n",
        "\n",
        "# Submission 1: SVM with preprocessing\n",
        "print(\"\\n1. SVM (preprocessed) submission\")\n",
        "svm_test_scores_prepro = svm_prepo_final.decision_function(X_test_prepro_final)\n",
        "from scipy.special import expit\n",
        "svm_test_proba_prepro = expit(svm_test_scores_prepro)\n",
        "\n",
        "submission_svm_prepro = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': svm_test_proba_prepro\n",
        "})\n",
        "submission_svm_prepro.to_csv('submission_svm_preprocessed.csv', index=False)\n",
        "print(\"  Saved: submission_svm_preprocessed.csv\")\n",
        "\n",
        "# Submission 2: Naive Bayes with preprocessing\n",
        "print(\"\\n2. Naive Bayes (preprocessed) submission\")\n",
        "nb_test_proba_prepro = nb_prepro_final.predict_proba(X_test_prepro_final)[:, 1]\n",
        "\n",
        "submission_nb_prepro = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': nb_test_proba_prepro\n",
        "})\n",
        "submission_nb_prepro.to_csv('submission_nb_preprocessed.csv', index=False)\n",
        "print(\"  Saved: submission_nb_preprocessed.csv\")\n",
        "\n",
        "# Submission 3: Ensemble with preprocessing\n",
        "print(\"\\n3. Ensemble (preprocessed) submission\")\n",
        "ensemble_test_proba_prepro = (svm_test_proba_prepro + nb_test_proba_prepro) / 2\n",
        "\n",
        "submission_ensemble_prepro = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': ensemble_test_proba_prepro\n",
        "})\n",
        "submission_ensemble_prepro.to_csv('submission_ensemble_preprocessed.csv', index=False)\n",
        "print(\"  Saved: submission_ensemble_preprocessed.csv\")\n",
        "\n",
        "print(\"\\nSUBMISSIONS USING ORIGINAL DATA (NO PREPROCESSING)\")\n",
        "\n",
        "# Submission 4: SVM without preprocessing\n",
        "print(\"\\n4. SVM (original) submission\")\n",
        "svm_test_scores = svm_final.decision_function(X_test_final)\n",
        "svm_test_proba = expit(svm_test_scores)\n",
        "\n",
        "submission_svm = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': svm_test_proba\n",
        "})\n",
        "submission_svm.to_csv('submission_svm_original.csv', index=False)\n",
        "print(\"  Saved: submission_svm_original.csv\")\n",
        "\n",
        "# Submission 5: Naive Bayes without preprocessing\n",
        "print(\"\\n5. Naive Bayes (original) submission\")\n",
        "nb_test_proba = nb_final.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "submission_nb = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': nb_test_proba\n",
        "})\n",
        "submission_nb.to_csv('submission_nb_original.csv', index=False)\n",
        "print(\"  Saved: submission_nb_original.csv\")\n",
        "\n",
        "# Submission 6: Ensemble without preprocessing\n",
        "print(\"\\n6. Ensemble (original) submission\")\n",
        "ensemble_test_proba = (svm_test_proba + nb_test_proba) / 2\n",
        "\n",
        "submission_ensemble = pd.DataFrame({\n",
        "    'ID': test_data['id'],\n",
        "    'label': ensemble_test_proba\n",
        "})\n",
        "submission_ensemble.to_csv('submission_ensemble_original.csv', index=False)\n",
        "print(\"  Saved: submission_ensemble_original.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuDNeUpv82Ov"
      },
      "source": [
        "## ‚úçÔ∏è Kaggle write-up\n",
        "\n",
        "**Manuel Agraz Vallejo**:\n",
        "\n",
        "**I submitted six submissions: Linear SVM, Naive Bayes, and Ensemble with and without data preprocessing. This preprocessing includes: converting everything to lower caps, removing all emojis, removing \"@\" handles, removed extra whitespace, and finally removing URLS. For the Linear SVM model I used the previously determined best C value of 0.56, and for my Naive Bayes model I used the previous alpha value of 0.24. I used Unigrams+Bigrams for the vectorizer. The ensemble model just uses the average prediction of both Linear SVM and NB models.**\n",
        "\n",
        "**In the end the pre-processing wasn't as useful as I was expecting as even though it simplified the vocabulary the model had to work with, it didn't outperform the models that just used the original data. On the bright side, the simple average ensemble of both models did outperform the individual SVM and NB models when using the original data achieving my best AUROC of 0.958.**\n",
        "\n",
        "**I learned that using feature engineering on the data isn't always going to improve performance, and the choice of how much to remove or modify from the original data isn't trivial, as it can actually end up reducing performance as shown by my submissions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VBJ-Uzzk7yIC"
      },
      "outputs": [],
      "source": [
        "#running this code block will convert this notebook and its outputs into a pdf report.\n",
        "# !jupyter nbconvert --to html /content/gdrive/MyDrive/Colab\\ Notebooks/IA3-2024.ipynb  # you might need to change this path to appropriate value to location your copy of the IA0 notebook\n",
        "\n",
        "# input_html = '/content/gdrive/MyDrive/Colab Notebooks/IA3-2024.html' #you might need to change this path accordingly\n",
        "# output_pdf = '/content/gdrive/MyDrive/Colab Notebooks/IA3output.pdf' #you might need to change this path or name accordingly\n",
        "\n",
        "# # Convert HTML to PDF\n",
        "# pdfkit.from_file(input_html, output_pdf)\n",
        "\n",
        "# # Download the generated PDF\n",
        "# files.download(output_pdf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml_class",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
